{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"./data/test.csv\", index_col=\"index\", low_memory=False)\n",
    "train_data = pd.read_csv(\"./data/train.csv\", index_col=\"index\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### How large is the training data set and the test data set?\n",
    "print(\"test data size: \", test_data.shape)\n",
    "print(\"train data size: \", train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train data\n",
    "train_data.target__office.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model Review\n",
    "\n",
    "In the provided baseline model, several ambiguous points require attention.\n",
    "\n",
    "### Feature Selection:\n",
    "\n",
    "- **Issue:** The reason for choosing specific columns as features is not clearly articulated.\n",
    "  \n",
    "- **Recommendation:** Begin by providing a rationale for the selection of these columns. Explain why each feature is relevant to the analysis, the problem at hand, or the domain.\n",
    "\n",
    "### Missing Values Handling:\n",
    "\n",
    "- **Issue:** Missing values (NaN) in the dataset have not been addressed.\n",
    "  \n",
    "- **Recommendation:** Implement a strategy for handling missing values, such as imputation or removal. Additionally, it's crucial to investigate whether the presence of NaN values conveys any meaningful information. Determine if the absence of data in certain columns holds significance and document your findings.\n",
    "\n",
    "### Feature Engineering and Selection:\n",
    "\n",
    "- **Issue:** The data analysis lacks a dedicated feature engineering and feature selection process.\n",
    "  \n",
    "- **Recommendation:** Explore and create new features that might enhance the model's predictive power. Additionally, consider employing techniques for feature selection to identify the most impactful variables. This step is essential for refining the model and improving its efficiency.\n",
    "\n",
    "## Jupyter Notebook Markup:\n",
    "\n",
    "```python\n",
    "# Exploratory Data Analysis Project Explanation\n",
    "\n",
    "## Baseline Model Review\n",
    "\n",
    "In the provided baseline model, several ambiguous points require attention.\n",
    "\n",
    "### Feature Selection:\n",
    "\n",
    "- **Issue:** The reason for choosing specific columns as features is not clearly articulated.\n",
    "\n",
    "- **Recommendation:** Begin by providing a rationale for the selection of these columns. Explain why each feature is relevant to the analysis, the problem at hand, or the domain.\n",
    "\n",
    "### Missing Values Handling:\n",
    "\n",
    "- **Issue:** Missing values (NaN) in the dataset have not been addressed.\n",
    "\n",
    "- **Recommendation:** Implement a strategy for handling missing values, such as imputation or removal. Additionally, it's crucial to investigate whether the presence of NaN values conveys any meaningful information. Determine if the absence of data in certain columns holds significance and document your findings.\n",
    "\n",
    "### Feature Engineering and Selection:\n",
    "\n",
    "- **Issue:** The data analysis lacks a dedicated feature engineering and feature selection process.\n",
    "\n",
    "- **Recommendation:** Explore and create new features that might enhance the model's predictive power. Additionally, consider employing techniques for feature selection to identify the most impactful variables. This step is essential for refining the model and improving its efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### numerical features\n",
    "train_data.select_dtypes(include=\"number\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[train_data.target__office == True][\"officearea\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[train_data.target__office == True][\"landuse\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data[train_data.target__office == False][\"officearea\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[train_data.target__office == False][\"landuse\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\"officearea\", \"comarea\", \"yearbuilt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data[feature_cols].copy(deep=True)\n",
    "y = train_data[\"target__office\"].copy(deep=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does my model perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"MSE:\", mean_squared_error(y_test.astype(int), y_hat.astype(int)))\n",
    "print(\"Accuracy:\", accuracy_score(y_test.astype(int), y_hat.astype(int)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
